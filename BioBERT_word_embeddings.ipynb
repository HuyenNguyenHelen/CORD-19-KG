{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BioBERT_word-embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMt8ca6ovIwnpJs6QM9i55i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/CORD-19-KG/blob/master/BioBERT_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODlr2qmKJML9"
      },
      "source": [
        "## Loading processed query and documents \n",
        "- processed query file: given by either using ngram tokenization, metamap extraction, keyword extraction, named entity recognition\n",
        "- processed documents given by either metamap extraction, keyword extraction, named entity recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QA3uGYiJ943"
      },
      "source": [
        "#### Query: keyword expansion\n",
        "#### Doc: ngram tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIvZYG2gKUli"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "ulUoJs1BJKUV",
        "outputId": "b4e77cf9-79f7-49b8-c665-e28ef155cb58"
      },
      "source": [
        "with open (r'/content/PRF_kwExtraction_Query2016_1-3gram.csv', 'r', encoding = 'cp1252') as f:\n",
        "  queries = pd.read_csv(f)\n",
        "queries.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>queryID</th>\n",
              "      <th>summary</th>\n",
              "      <th>summary_keyword</th>\n",
              "      <th>description</th>\n",
              "      <th>description_keyword</th>\n",
              "      <th>note</th>\n",
              "      <th>note_keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A 78 year old male presents with frequent stoo...</td>\n",
              "      <td>{'male': 0.29736558256021506, 'presents': 0.29...</td>\n",
              "      <td>78 M transferred to nursing home for rehab aft...</td>\n",
              "      <td>{'approximately': 0.3881970960906714, 'melanot...</td>\n",
              "      <td>78 M w/ pmh of CABG in early [**Month (only...</td>\n",
              "      <td>{'nursing': 0.16048483002786335, 'home': 0.160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>An elderly female with past medical history of...</td>\n",
              "      <td>{'elderly': 0.15831692877998726, 'female': 0.1...</td>\n",
              "      <td>An elderly female with past medical history of...</td>\n",
              "      <td>{'elderly': 0.16383273847958243, 'female': 0.1...</td>\n",
              "      <td>Ms [**Known patient lastname 241**] is a [*...</td>\n",
              "      <td>{'hyperlipidemia': 0.14664469725594667, 'Ortho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>A 75F found to be hypoglycemic with hypotensio...</td>\n",
              "      <td>{'leukocytosis': 0.5590855488092952, 'creatini...</td>\n",
              "      <td>A 75F with a PMHx significant for severe PVD, ...</td>\n",
              "      <td>{'hypotension and confusion': 0.18857126108325...</td>\n",
              "      <td>Pt is a 75F with a PMHx significant for sev...</td>\n",
              "      <td>{'unresponsive at home': 0.16805088855153935, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                       note_keyword\n",
              "0           0  ...  {'nursing': 0.16048483002786335, 'home': 0.160...\n",
              "1           1  ...  {'hyperlipidemia': 0.14664469725594667, 'Ortho...\n",
              "2           2  ...  {'unresponsive at home': 0.16805088855153935, ...\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "AqJSl7x0LZpi",
        "outputId": "6f756b3a-3be3-4fc1-96b3-e3e7fdd3311a"
      },
      "source": [
        "with open (r'/content/ngram_token_brief_titles.csv', 'r', encoding = 'utf-8') as f:\n",
        "  docs = pd.read_csv(f)\n",
        "docs.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>queryID</th>\n",
              "      <th>brief_title</th>\n",
              "      <th>ngrams_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Dabrafenib and Trametinib in Treating Patients...</td>\n",
              "      <td>['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Dabrafenib and Trametinib in Treating Patients...</td>\n",
              "      <td>['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Functionality of an 8-Channel Paddle Coil for ...</td>\n",
              "      <td>['Functionality', 'of', 'an', '8-Channel', 'Pa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                      ngrams_tokens\n",
              "0           0  ...  ['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...\n",
              "1           1  ...  ['Dabrafenib', 'and', 'Trametinib', 'in', 'Tre...\n",
              "2           2  ...  ['Functionality', 'of', 'an', '8-Channel', 'Pa...\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd6YusKRg7-G",
        "outputId": "3942d137-ec90-4acb-c600-8c58796495ea"
      },
      "source": [
        "!pip install biobert-embedding==0.1.2\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biobert-embedding==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/f0/f5bd3fd4a0bcef4d85e5e82347ae73d376d68dc8086afde75838ba0473a2/biobert-embedding-0.1.2.tar.gz\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/65/5248be50c55ab7429dd5c11f5e2f9f5865606b80e854ca63139ad1a584f2/torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 13kB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from biobert-embedding==0.1.2) (2.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0->biobert-embedding==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/77/cc19511d0fe4672890209ebcbfb9b3f4746572f5a48f7ed2654e7f8c2f29/boto3-1.17.89-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.6.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.34.1)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding==0.1.2) (0.12.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2.10)\n",
            "Collecting botocore<1.21.0,>=1.20.89\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/e6e16f588036b387d4f4f8e2e780a520e2b3925ba1529fdfc97ad909fb6c/botocore-1.20.89-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 47.6MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.30.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (57.0.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->biobert-embedding==0.1.2) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.89->boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding==0.1.2) (2.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->biobert-embedding==0.1.2) (3.1.0)\n",
            "Building wheels for collected packages: biobert-embedding\n",
            "  Building wheel for biobert-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for biobert-embedding: filename=biobert_embedding-0.1.2-cp37-none-any.whl size=5701 sha256=1f43c0d6c4069acbb28a28570ebc3154309429682ae0b52985510e231df70f3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/15/65/3fc6192a7cb7920672bb46d566173decb0875f35bbe03cd09d\n",
            "Successfully built biobert-embedding\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.20.89 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, biobert-embedding\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed biobert-embedding-0.1.2 boto3-1.17.89 botocore-1.20.89 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2 torch-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSRQPtOdDKHB"
      },
      "source": [
        "from biobert_embedding.embedding import BiobertEmbedding\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def bioBERT_topsim (query_term, doc_terms,k):\n",
        "    cos_sim = {}\n",
        "    query_vec = bioBERTfit(query_term)\n",
        "    for item in doc_terms:\n",
        "        cos_sim[item] = cal_cosine_sim(bioBERTfit(item), query_vec)\n",
        "    top_sim_terms = most_similar (cos_sim, k)\n",
        "    return top_sim_terms\n",
        "        \n",
        "def bioBERTfit(word):\n",
        "    biobert = BiobertEmbedding()\n",
        "    vec_w = biobert.word_vector(word)\n",
        "    return vec_w\n",
        "    \n",
        "def cal_cosine_sim(single_vec_query, sing_vec):\n",
        "    cosine_sim = cosine_similarity(single_vec_query[0].reshape(1, -1),sing_vec[0].reshape(1, -1))\n",
        "    return cosine_sim\n",
        "\n",
        "def most_similar(dic, k_):\n",
        "    # Sort the given array arr in reverse order.   \n",
        "    # Print the first kth largest elements\n",
        "    sort_dic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse = True)[:k_]}\n",
        "    return sort_dic\n",
        "    \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aokYaU3D7Ee",
        "outputId": "d58bd38d-472f-48eb-f09f-222d88f64527"
      },
      "source": [
        "# Example\n",
        "query = 'work'\n",
        "doc_terms = ['job', 'sky', 'sweet tea', 'do', 'scientific papers', 'working', 'high performance']\n",
        "\n",
        "bioBERT_topsim (query, doc_terms, 3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading the biobert model, will take a minute...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'do': array([[0.829417]], dtype=float32),\n",
              " 'job': array([[0.8601637]], dtype=float32),\n",
              " 'working': array([[0.88085926]], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7VzNHUfNB1p"
      },
      "source": [
        "#### Fitting model into the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xDLKrxdM_lN"
      },
      "source": [
        "import ast\n",
        "top_sim_by_q = []\n",
        "for q, d in zip (queries['summary_keyword'], docs['ngrams_tokens']):\n",
        "  q = ast.literal_eval(q)\n",
        "  d = ast.literal_eval(d)\n",
        "  term_top_sim = {}\n",
        "  for term in q.keys():\n",
        "    term_top_sim[term] = bioBERT_topsim (term, d,5)\n",
        "  top_sim_by_q.append(term_top_sim)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsBTpZJpbL21"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}