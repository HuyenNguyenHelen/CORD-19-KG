{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid-19-kg-mining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/CORD-19-KG/blob/master/QA-models/covid_19_kg_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUFXMJVdOltr"
      },
      "source": [
        "## Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7TZVvkzNwDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e3426d-61a6-4574-e40c-75cee6642dce"
      },
      "source": [
        "# If using Google Colab run this cell \n",
        "\n",
        "# select tensorflow version for colab \n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h22uybHCOUyq",
        "outputId": "b04a182b-31c8-4190-87ba-357659d28235"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "print('TensorFlow  version: {}'.format(tf.__version__))\n",
        "\n",
        "# Get the GPU name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow  version: 1.15.2\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgZPAPapOaLA"
      },
      "source": [
        "%%capture \n",
        "# Install AmpliGraph library\n",
        "! pip install ampligraph\n",
        "\n",
        "# Required to visualize embeddings with tensorboard projector, comment out if not required!\n",
        "! pip install --user tensorboard\n",
        "\n",
        "# Required to plot text on embedding clusters, comment out if not required!\n",
        "! pip install --user git+https://github.com/Phlya/adjustText"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bzg5vHqOfch",
        "outputId": "e7736aea-d876-4044-caba-e451c156e7bf"
      },
      "source": [
        "# All imports used in this tutorial \n",
        "%tensorflow_version 1.x\n",
        "import ampligraph\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from ampligraph.datasets import load_fb15k_237\n",
        "from ampligraph.evaluation import train_test_split_no_unseen, evaluate_performance, mr_score, mrr_score, hits_at_n_score\n",
        "from ampligraph.discovery import query_topn, discover_facts, find_clusters\n",
        "from ampligraph.latent_features import TransE, ComplEx, HolE, DistMult, ConvE, ConvKB\n",
        "from ampligraph.utils import save_model, restore_model\n",
        "\n",
        "def display_aggregate_metrics(ranks):\n",
        "    print('Mean Rank:', mr_score(ranks)) \n",
        "    print('Mean Reciprocal Rank:', mrr_score(ranks)) \n",
        "    print('Hits@1:', hits_at_n_score(ranks, 1))\n",
        "    print('Hits@10:', hits_at_n_score(ranks, 10))\n",
        "    print('Hits@100:', hits_at_n_score(ranks, 100))\n",
        "\n",
        "print('Ampligraph version: {}'.format(ampligraph.__version__))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ampligraph version: 1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k96fp70dOyyS"
      },
      "source": [
        "from ampligraph.datasets import load_fb15k_237, load_wn18rr, load_yago3_10\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBb8eVx6Osxx"
      },
      "source": [
        "## Loading Data \n",
        "(a triples dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woNtfTQ2bRgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "79e93cd6-03dc-4a33-c26a-84f478e27a90"
      },
      "source": [
        "# Downloading the csv file from your GitHub account\n",
        "# re_pdf = requests.get('https://raw.githubusercontent.com/HuyenNguyenHelen/CORD-19-KG/master/Data/new_triples_with_predefined_relations_pdf_June20_.csv').content\n",
        "# re_pmc = requests.get('https://raw.githubusercontent.com/HuyenNguyenHelen/CORD-19-KG/master/Data/new_triples_with_predefined_relations_pmc_June20_.csv').content\n",
        "# pdf = pd.read_csv(io.StringIO(re_pdf.decode('utf-8')))\n",
        "# pmc =  pd.read_csv(io.StringIO(re_pmc.decode('utf-8')))\n",
        "# dataset = pd.concat([pmc, pdf])\n",
        "\n",
        "re_dataset = requests.get('https://raw.githubusercontent.com/HuyenNguyenHelen/CORD-19-KG/master/Data/all-final-cleaned-triples_2.csv').content\n",
        "dataset = pd.read_csv(io.StringIO(re_dataset.decode('utf-8')))\n",
        "\n",
        "print(dataset.columns)\n",
        "dataset.drop(columns='Unnamed: 0', inplace=True)\n",
        "# dataset = dataset[['subject','new_relation', 'object' ]]\n",
        "dataset.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'subject', 'new_relation', 'object'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a49388ef-c249-456d-aa34-9ad4c82bada0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>new_relation</th>\n",
              "      <th>object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dysfunction</td>\n",
              "      <td>disease_species</td>\n",
              "      <td>child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>et dysfunction</td>\n",
              "      <td>disease_species</td>\n",
              "      <td>child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rsv</td>\n",
              "      <td>disease_disease</td>\n",
              "      <td>virus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>treatment</td>\n",
              "      <td>treat_procedure_species</td>\n",
              "      <td>child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>urgency</td>\n",
              "      <td>disease_disease</td>\n",
              "      <td>virus</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a49388ef-c249-456d-aa34-9ad4c82bada0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a49388ef-c249-456d-aa34-9ad4c82bada0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a49388ef-c249-456d-aa34-9ad4c82bada0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          subject             new_relation object\n",
              "0     dysfunction          disease_species  child\n",
              "1  et dysfunction          disease_species  child\n",
              "2             rsv          disease_disease  virus\n",
              "3       treatment  treat_procedure_species  child\n",
              "4         urgency          disease_disease  virus"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne21mIAeO-Kh",
        "outputId": "9eecaffc-d3bf-40c7-bddb-521f12658fb9"
      },
      "source": [
        "print('Total triples in the KG:', dataset.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total triples in the KG: (86275, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WxrnxjodccM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2940d83c-4ad3-4fce-dfce-a115b96067db"
      },
      "source": [
        "print('the number of relations: \\n', dataset['new_relation'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of relations: \n",
            " disease_disease                    22991\n",
            "gene_gene                          10985\n",
            "gene_disease                        6347\n",
            "disease_species                     5956\n",
            "disease_gene                        5684\n",
            "treat_procedure_disease             3757\n",
            "disease_treat_procedure             3471\n",
            "gene_treat_procedure                2618\n",
            "drug_disease                        2420\n",
            "treat_procedure_gene                2287\n",
            "gene_species                        2140\n",
            "treat_procedure_treat_procedure     2115\n",
            "drug_gene                           2040\n",
            "gene_drug                           1539\n",
            "drug_drug                           1505\n",
            "disease_symptom                     1475\n",
            "disease_drug                        1407\n",
            "symptom_disease                     1296\n",
            "treat_procedure_species             1214\n",
            "drug_treat_procedure                1124\n",
            "treat_procedure_drug                1094\n",
            "drug_species                         892\n",
            "symptom_symptom                      528\n",
            "gene_symptom                         276\n",
            "symptom_species                      265\n",
            "treat_procedure_symptom              262\n",
            "symptom_treat_procedure              198\n",
            "symptom_gene                         171\n",
            "drug_symptom                         148\n",
            "symptom_drug                          70\n",
            "Name: new_relation, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration"
      ],
      "metadata": {
        "id": "EWBK-F1u4StA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing\n",
        "Partition the triples into 10 portions that will be used for buiding QA systems"
      ],
      "metadata": {
        "id": "Faxo3McGqype"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1, axis=1).reset_index(drop=True)\n",
        "subsets = np.array_split(dataset, 10)  \n",
        "len(subsets)\n"
      ],
      "metadata": {
        "id": "pscvKD-2tIXP",
        "outputId": "de2f7680-dcfb-46ed-8a8d-afe96fa08546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Developing QA system"
      ],
      "metadata": {
        "id": "nYe9PkDzrmgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Developing model"
      ],
      "metadata": {
        "id": "tGBIAwfSr_xJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLlcSqIBPEAQ"
      },
      "source": [
        "### Create training, validation and test splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaZipgBpPGop"
      },
      "source": [
        "from ampligraph.evaluation import train_test_split_no_unseen\n",
        "def train_set_split (ds, test_frac = 200, val_frac = 100 ):\n",
        "  # get the validation set of size 500\n",
        "  test_train, X_test = train_test_split_no_unseen(ds.values, test_frac, seed=0)\n",
        "\n",
        "  # get the test set of size 1000 from the remaining triples\n",
        "  X_train, X_val = train_test_split_no_unseen(test_train, val_frac, seed=0)\n",
        "\n",
        "  print('Total triples:', dataset.shape)\n",
        "  print('Size of train:', X_train.shape)\n",
        "  print('Size of valid:', X_val.shape)\n",
        "  print('Size of test:', X_test.shape)\n",
        "  return X_train, X_val, X_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzsmWo0zPMR6"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9POL-1mPOsJ",
        "outputId": "9c079d9c-7879-4aa8-a876-8ceeb112f71e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from ampligraph.latent_features import TransE\n",
        "\n",
        "def training (train_ds, val_ds, test_ds):\n",
        "  # Train a KGE model\n",
        "  model = TransE(k=300, \n",
        "                epochs=100, \n",
        "                eta=1, \n",
        "                loss='multiclass_nll', \n",
        "                initializer='xavier', initializer_params={'uniform': False},\n",
        "                regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},\n",
        "                optimizer= 'adam', optimizer_params= {'lr': 0.0001}, \n",
        "                seed= 0, batches_count= 100, verbose=True)\n",
        "\n",
        "  model.fit(train_ds)\n",
        "  # ----------------------\n",
        "  # Evaluate: \n",
        "  # Filtered evaluation with ranking strategy assigning worst rank to break ties\n",
        "  from ampligraph.utils import save_model, restore_model\n",
        "  save_model(model, 'TransE.pkl')\n",
        "  model = restore_model('TransE.pkl')\n",
        "\n",
        "  # create the filter \n",
        "  X_filter = np.concatenate([train_ds, val_ds, test_ds], 0)\n",
        "\n",
        "  # compute ranks\n",
        "  ranks = evaluate_performance(test_ds, \n",
        "                              model=model, \n",
        "                              filter_triples=X_filter)\n",
        "\n",
        "  # ranks are computed per triple\n",
        "  print('Test set:', X_test.shape)\n",
        "  print('Size of ranks:', ranks.shape)\n",
        "\n",
        "  # Aggregate metrics show the aggregate performance of the model on the test set using a single number\n",
        "  display_aggregate_metrics(ranks)\n",
        "  # ----------------------\n",
        "  \n",
        "  return display_aggregate_metrics(ranks)\n",
        "\n",
        "X_train, X_val, X_test = train_set_split(dataset)\n",
        "scores = training (X_train, X_val, X_test) #dataset.to_numpy()\n",
        "print('........score: \\n {}'.format(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total triples: (86275, 3)\n",
            "Size of train: (85975, 3)\n",
            "Size of valid: (100, 3)\n",
            "Size of test: (200, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average TransE Loss:   0.023191:  61%|██████    | 61/100 [01:06<00:36,  1.06epoch/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYMsDmRuQLem"
      },
      "source": [
        "## Knowledge Discovery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ampligraph.discovery import query_topn\n",
        "\n",
        "def QA_retrieve (input, top_n ):\n",
        "  head, relation1, tail = input[0], input[1], input[2]\n",
        "  if len(relation1.split('_')) <= 2:\n",
        "    relation2 = '{}_{}'.format(relation1.split('_')[1], relation1.split('_')[0])\n",
        "  elif len(relation1.split('_')) == 3:\n",
        "     relation2 = '{}_{}_{}'.format(relation1.split('_')[1], relation1.split('_')[2], relation1.split('_')[0])\n",
        "  else:\n",
        "    raise ValueError('error: relation length issue')\n",
        "  # restore the previously saved model to save time\n",
        "  model = restore_model('TransE.pkl')\n",
        "  if relation1  in dataset['new_relation'].tolist():\n",
        "    triples1, scores1 = query_topn(model, top_n=top_n, \n",
        "                                head=head, \n",
        "                                relation=relation1, \n",
        "                                tail=tail, \n",
        "                                ents_to_consider=None, \n",
        "                                rels_to_consider=None)\n",
        "  else:\n",
        "    triples1, scores1 = [], []\n",
        "\n",
        "  if relation2  in dataset['new_relation'].tolist():\n",
        "    triples2, scores2 = query_topn(model, top_n=top_n, \n",
        "                                head=tail, \n",
        "                                relation=relation2, \n",
        "                                tail=head, \n",
        "                                ents_to_consider=None, \n",
        "                                rels_to_consider=None)\n",
        "  else:\n",
        "    triples2, scores2 = [], []\n",
        "\n",
        "  if len(triples1) + len(triples2) == top_n:\n",
        "    if len(triples1) ==0: \n",
        "      triples = triples1 + triples2.tolist()\n",
        "      scores = scores1+ scores2.tolist()\n",
        "    else:\n",
        "      triples = triples1.tolist() + triples2\n",
        "      scores = scores1.tolist() + scores2\n",
        "  else:\n",
        "    end_idx = round(top_n/2)\n",
        "    triples = triples1.tolist()[:end_idx] + triples2.tolist()[:end_idx]\n",
        "    scores = scores1.tolist()[:end_idx] + scores2.tolist()[:end_idx]\n",
        "   \n",
        "  for triple, score in zip(triples, scores):\n",
        "      print('Score: {} \\t {} '.format(score, triple))\n",
        "  return triples, scores\n",
        " \n"
      ],
      "metadata": {
        "id": "MnG3epqEU5Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Query1: What are the genes/proteins related to Covid-19\n",
        "print ('------------------------------------------------------------')\n",
        "print('What are the genes/proteins related to Covid-19')\n",
        "question3 = QA_retrieve (['covid-19', 'disease_gene', None], top_n = 20)\n",
        "\n",
        "# Query2: What species transmit the covid-19\n",
        "print ('------------------------------------------------------------')\n",
        "print('What species transmit the covid-19?')\n",
        "question4 = QA_retrieve (['covid-19', 'disease_species', None], top_n = 20)\n",
        "\n",
        "# Query3: what are symptoms of the covid-19\n",
        "print ('------------------------------------------------------------')\n",
        "print('what are symptoms of the covid-19?')\n",
        "question5 = QA_retrieve (['covid-19', 'disease_symptom', None], top_n = 20)\n",
        "\n",
        "# Query4: what are the possible therapeutic procedure of covid-19??\n",
        "print ('------------------------------------------------------------')\n",
        "print('what are the possible therapeutic procedure of covid-19?')\n",
        "question1 = QA_retrieve (['covid-19', 'disease_treat_procedure', None], top_n = 20)\n",
        "\n",
        "# Query5: What are potential drugs to treat COVID-19?\n",
        "print ('------------------------------------------------------------')\n",
        "print('What are potential drugs to treat COVID-19?')\n",
        "question6 = QA_retrieve (['covid-19', 'disease_drug', None], top_n = 20)\n",
        "\n",
        "# Query6: What are related diseases of Covid-19\n",
        "print ('------------------------------------------------------------')\n",
        "print('What are related diseases of Covid-19')\n",
        "question2 = QA_retrieve (['covid-19', 'disease_disease', None], top_n = 20)\n"
      ],
      "metadata": {
        "id": "5opzaNdZ-DtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model, and Knowledge mining with different % of dataset"
      ],
      "metadata": {
        "id": "KVt7GYrB65gq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-wl5yQgLRat"
      },
      "source": [
        "ALL = []\n",
        "\n",
        "for idx in range(len(subsets)):\n",
        "  outputs = {} \n",
        "  outputs['subset_%s' %(idx+1)] = []\n",
        "  data = subsets[:idx+1]\n",
        "  data_concat = pd.concat(data)\n",
        "  print ('i: {} -- len: {}'.format(idx, len(data_concat)))\n",
        "\n",
        "  # Spliting dataset for training\n",
        "  X_train, X_val, X_test = train_set_split(data_concat)\n",
        "  # Training...\n",
        "  print('Training..........')\n",
        "  training (X_train, X_val, X_test)\n",
        "\n",
        "  # Retrieving\n",
        "  # Query1: What are the genes/proteins related to Covid-19\n",
        "  print ('------------------------------------------------------------')\n",
        "  print('What are the genes/proteins related to Covid-19')\n",
        "  question3 = QA_retrieve (['covid-19', 'disease_gene', None], top_n = 20)\n",
        "  df3 = pd.DataFrame(zip(question3[0],question3[1]), columns = ['triple', 'score'])\n",
        "  outputs['subset_%s' %(idx+1)].append(df3)\n",
        "\n",
        "  # Query2: What species transmit the covid-19\n",
        "  print ('------------------------------------------------------------')\n",
        "  print('What species transmit the covid-19?')\n",
        "  question4 = QA_retrieve (['covid-19', 'disease_species', None], top_n = 20)\n",
        "  df4 = pd.DataFrame(zip(question4[0],question4[1]), columns = ['triple', 'score'])\n",
        "  outputs['subset_%s' %(idx+1)].append(df4)\n",
        "\n",
        "  # Query3: what are symptoms of the covid-19\n",
        "  print ('------------------------------------------------------------')\n",
        "  print('what are symptoms of the covid-19?')\n",
        "  question5 = QA_retrieve (['covid-19', 'disease_symptom', None], top_n = 20)\n",
        "  df5 = pd.DataFrame(zip(question5[0],question5[1]), columns = ['triple', 'score'])\n",
        "  outputs['subset_%s' %(idx+1)].append(df5)\n",
        "\n",
        "  # Query4: what are the possible therapeutic procedure of covid-19??\n",
        "  print ('------------------------------------------------------------')\n",
        "  print('what are the possible therapeutic procedure of covid-19?')\n",
        "  question1 = QA_retrieve (['covid-19', 'disease_treat_procedure', None], top_n = 20)\n",
        "  df1 = pd.DataFrame(zip(question1[0],question1[1]), columns = ['triple', 'score'])\n",
        "  outputs['subset_%s' %(idx+1)].append(df1)\n",
        "\n",
        "  #Query5: What are potential drugs to treat COVID-19?\n",
        "  print ('------------------------------------------------------------')\n",
        "  print('What are potential drugs to treat COVID-19?')\n",
        "  question6 = QA_retrieve (['covid-19', 'disease_drug', None], top_n = 20)\n",
        "  df6 = pd.DataFrame(zip(question6[0],question6[1]), columns = ['triple', 'score'])\n",
        "  outputs['subset_%s' %(idx+1)].append(df6)\n",
        "\n",
        "  # Query6: What are related diseases of Covid-19\n",
        "  print ('------------------------------------------------------------')\n",
        "  print('What are related diseases of Covid-19')\n",
        "  question2 = QA_retrieve (['covid-19', 'disease_disease', None], top_n = 20)\n",
        "  df2 = pd.DataFrame(zip(question2[0],question2[1]), columns = ['triple', 'score'])\n",
        "  outputs['subset_%s' %(idx+1)].append(df2)\n",
        "\n",
        "  ALL.append(outputs)\n",
        "                     \n",
        "                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALL"
      ],
      "metadata": {
        "id": "_O-Vh1ipisf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "dir_path = '/content/drive/MyDrive/KG-output-2'\n",
        "isExist = os.path.exists(dir_path)\n",
        "\n",
        "if not isExist:\n",
        "  os.makedirs(dir_path)\n",
        "\n",
        "for i in range(len(ALL)): \n",
        "  print('i----------%s'%i)\n",
        "  dir_s_path = '/content/drive/MyDrive/KG-output-2/subset_%s'%str(i+1)\n",
        "  isExist_s = os.path.exists(dir_s_path)\n",
        "  if not isExist_s:\n",
        "    dir = os.makedirs(dir_s_path)\n",
        "  for j  in range(len(list(ALL[i].values())[0])):\n",
        "    print('j----------%s'%j)\n",
        "    path = '/content/drive/MyDrive/KG-output-2/subset_%s'%str(i+1) +'/query_' + str(j) + '.csv'\n",
        "    print(path)\n",
        "    print((list(ALL[i].values()))[0][j])\n",
        "    with open(path, 'w') as file:\n",
        "      (list(ALL[i].values()))[0][j].to_csv(file)\n",
        "\n"
      ],
      "metadata": {
        "id": "x8tEos2PHOi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA EVALUATION"
      ],
      "metadata": {
        "id": "j_GEdabCLb7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load groundtruth file\n"
      ],
      "metadata": {
        "id": "sBHN0WDXLj7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}